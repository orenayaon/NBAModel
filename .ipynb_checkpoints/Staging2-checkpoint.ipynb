{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Load Libraries\nfrom datetime import date\nimport pyodbc\nimport pandas as pd\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import SQLContext\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nfrom sportsreference.nba.teams import Teams\nimport pandas.io.sql as psql",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#for development in azure notebooks (databricks uses spark behind the scenes and does not require this step)\nsc = SparkContext('local')\nspark = SparkSession(sc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Create Dataframe\nDimTeam = pd.DataFrame()\n\n#Load Team name and Abbreviation into Dataframe\nfor x in range(2000,2020):\n    for team in Teams(x):\n      DimTeam = DimTeam.append({'Name':team.name,'Abbreviation':team.abbreviation},ignore_index='true')\n    x=x+1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#load into spark dataframe\nDimTeamSparkDF = spark.createDataFrame(DimTeam)\n#columnsToHash = [x for x in DimTeamSparkDF.columns if str(x) not in ['Columns to ignore here']]\n#DimTeamSparkDF = DimTeamSparkDF.withColumn(\"RowValueHash\", sha2(concat_ws(\"|\", *columnsToHash), 256))\nDimTeamSparkDF.createOrReplaceTempView(\"DimTeam\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#select * from df\nsqlQuery = 'Select distinct * \\\n            from DimTeam \\\n            Order By name desc' \nspark.sql(sqlQuery).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Connect to SQL Database\nserver = 'mintdatabase.database.windows.net' \ndatabase = 'NBADataMart' \nusername = 'oren' \npassword = 'Gpeqlx33j59o' \ncnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\ncursor = cnxn.cursor()\n\n#df = cursor.execute('Select * from DimTeam')\ncursor = cnxn.cursor()\nsql = \"SELECT * FROM DimTeam\"\n\ndf = psql.read_sql(sql, cnxn)\ncnxn.close()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "merge = pd.merge(df,DimTeamSparkDF,on=['Abbreviation','Name'])",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "name": "python36",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/ x - python",
      "nbconvert_exporter": "python",
      "version": "3.6.0",
      "name": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython2",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}